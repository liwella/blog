---
title: 流量控制算法分析
author: 青蛙瓷器
img: 'http://pic.tanzhang.work/blog/gallary/221108.jpg!up.webp'
top: false
cover: 'http://pic.tanzhang.work/blog/gallary/221108.jpg!up.webp'
toc: true
mathjax: false
categories: 算法
tags:
  - 限流
abbrlink: dad9d21e
date: 2022-11-08 22:11:51
coverImg:
---
任何服务器的cpu、内存、网络等资源都不是无限的，当系统的资源不足以支撑外部突发请求洪峰时，就会导致系统瘫痪，这时就要对系统实施保护机制，限制外部请求到系统的数量，这个保护的机制就是我们所说的“限流”；

要做到合理的限流，需要妥善的解决好以下三个问题：

1. 依据什么进行限流：需要考虑 对系统哪部分进行限流，限流控制力度多大等，这些如果无法在设计阶段给出准确的结果，就需要等系统上线运行一段时间后，根据具体情况来进行评估；
2. 如何进行限流：如何做到对请求进行限流，需要掌握常用的限流设计模式；
3. 流量超额如何进行处理：流量超额后有不同的处理方式，可以对超额后的请求直接采取丢弃的措施，这种被称为否决式限流；另一种方式是将超额后的请求放到队列中，等到系统空出资源以后再进行处理，这种被称为阻塞式限流；

## 流量统计指标

要做限流，就要先弄清楚哪些指标能够用来反映系统流量压力的大小，常见的有如下几个指标：

- 每秒事务数（Transaction per seconds，TPS）：TPS是衡量系统吞吐量的最终标准，“事务”可以理解为逻辑上的原子操作，即一笔完整的业务操作，例如支付，就是一笔完整的业务操作；
- 每秒请求数（Hits per seconds，HPS）：即客户端每秒向服务端发起的请求数，如果一个请求可以完成一笔业务，那 HPS 跟 TPS 是等价的；事实上，HPS 跟 TPS 很少是等价的，一笔业务操作通常会需要多次请求才能完成，例如一次支付通常会涉及到扫码，确认支付等动作；
- 每秒查询书（Queries per seconds，QPS）：指 **一台服务器** 每秒能响应的查询数，如果只有一台服务器，那么 QPS 跟 HPS 是等价的，但是分布式系统中往往不只一台服务器，一个请求可能涉及到多个服务器之间的远程调用，也就有多次服务器响应，及多个QPS；

通常情况下我们当然希望使用 TPS 来作为限流指标，用户进行操作时通常不会关注其中有多少个请求，又有多少个相应；但是，不同的业务对系统产生的压力是不一样的，一个事务操作通常包含了多个请求操作，这其中涉及了多个业务处理，这多个业务给系统的压力是不一样的，所以不能准确的反应系统所承受的压力；

主流系统通常选择 HPS 来作为限流指标，它是相对比较直观的，一定程度上能够反映处当前系统所承受的流量压力；但这并不说明 HPS 适合所有的系统，例如网络游戏等基于长连接的应用，则会把当前登录的用户数作为流量统计的指标，当在线用户数达到一定限制以后，后面登录的用户就需要进行排队等待；

## 限流设计模式

常用的限流设计模式包括以下四种：计数器模式、滑动窗口模式、漏桶模式、令牌桶模式；

### 计数器模式

计计数器模式通过设置一个计数器来统计当前时间的流量计数，如果这个数值达到了阈值，则对后续的请求进行限流；假设现在流量阈值为100TPS，在任何一秒内，如果发现超过100次事务请求，则会直接拒绝掉后续的请求。计数器模式很好理解，但是其本身缺点也比较明显：计数器模式虽然可以按照每秒来统计流量计数，但并不能保证任何一秒内的流量都不超过阈值，假设连续两秒内都产生了 70TPS 的请求，但是这 70TPS 请求分别集中在前一秒的后 0.5 秒，和后一秒的前 0.5 秒内，那么中间这一秒的请求是达到了 140TPS 的，超过了阈值 100TPS；

产生这种问题的根本原因在于计数器模式只对时间点进行了离散的统计，为了解决这种问题，滑动窗口模式这种更为平滑的统计模式诞生了。

### 滑动窗口模式

![滑动窗口模式](https://pic.tanzhang.work/blog/flow_window.png!up.webp)

滑动窗口的原理如上图所示，黑色长条为时间轴，灰色块为滑动时间窗口。假设流量的阈值为 5TPS，滑动窗口从左往右滑动，以当前时刻为基准，统计过去一秒钟的时间窗口内已经处理完成的事务请求数，从图中可以看出近一秒钟内处理完的事务数量为4个，及 4TPS，小于阈值 5TPS；如果窗口内已处理请求数为 5 个，即达到阈值，此时再有请求过来，会被拒绝；

滑动窗口模式很好的解决了计数器模式的离散统计问题，可以保证任意时间片段内的请求处理次数不会超过阈值；但是，它也有缺点，它只适用于否决式限流，对超过阈值的请求只能强制降级或失败，很难进行阻塞处理；下面将要介绍的漏桶模式和令牌桶模式就很好的解决了这个问题。

### 漏桶模式

漏桶模式 叫 漏斗模式 可能更加贴切，漏桶模式的原理，可以理解为 一个漏斗，以 X 的速度往漏斗中注水，漏斗底部出水口以 Y 的速度出水。将请求理解为水流，而请求的缓冲区则可以理解为漏斗，用于缓冲请求，防止请求直接失败或降级。当 Y > X 时，即出水口流水速度大于注水速度，漏斗永远不会被注满。而当 X > Y 时，注水速度大于出水速度，水流会被缓冲到漏斗当中，但是，由于漏斗的大小不能是无限大的，所以总会有被注满的时候，一旦漏斗被注满了，多余的水就会溢出，请求的角度来看，可以理解为请求直接失败或降级了。

漏桶模式的实现非常简单，其结构其实就是以一个以请求作为元素的 **先入先出** 队列，队列的长度就是缓冲区的大小，当队列满时就会拒绝后续请求的入队。水的流速可以理解为从队列中获取并处理请求的速度，是一个固定的值。

漏桶算法的难度其实主要就是 确定桶的大小 和 确定合理的流速，如果桶过大，会导致缓存的请求过多，处理速度跟不上，导致缓存的请求超时。而桶过小则会导致错误的将部分本来可以被正常处理的请求降级或失败；流出速率是一个固定值，对于固定数量的服务，可能是好的，但是对于具有伸缩功能的服务，或许能够动态调整请求处理速度的算法会更好。

### 令牌桶模式

漏桶模式是从出水口出水，而令牌桶则是往令牌桶中放入令牌。假设系统在 X 秒内可以处理 Y 个请求，那么系统就以 Y/X 的速率往令牌桶中放入令牌。请求到达系统前，必须先获取到令牌，才能进入系统被处理。当令牌桶中的令牌被全部取出后，再有新的请求进入时，由于无法获取到令牌，就会立马进入失败或降级；

令牌桶跟漏桶一样，其设计的关键在于令牌桶的大小和放入令牌的速率；令牌桶的大小也就是缓冲区的大小，当桶中令牌达到最大值时，就不再往桶中放入令牌。而放入令牌的速率，可以由系统的处理速度来决定，如果系统每秒钟可以处理100个请求，那么应该没 1/100 s 钟往令牌桶放入一个令牌；

令牌桶模式并不需要真的专门设计一个线程去往桶中放入令牌，只需要记录好上一个请求从桶中获取令牌的时间点，当下一个请求来获取令牌时，首先计算当前时间和上一次获取令牌的时间差，得到的结果再除以放令牌的时间间隔，就得出应该往桶中放入多少个令牌，然后一次性放入即可。

当系统处理请求的速度并不固定，却存在上限时，就产生了令牌桶模式一种变体。可以将上限大小作为令牌桶的大小，当有请求过来时，先从令牌桶中获取令牌，然后进入系统处理，在此过程中，系统并不会往桶中放入新的令牌。如果桶中令牌被全部取出，后续请求就需要进入排队或强制降级处理，直到系统中有一个正在处理的请求被处理完毕，往令牌桶中放入一块令牌，新的请求过来才能够获取到令牌进入处理。

## 总结

关于流量控制的分析到这里就结束了。限流的模式是多种多样的，其实现也并不困难，真正的难点在于设计出合理的限流：找到应该实施限流的位置，确定合理的流量统计指标，设计好流量超额后的处理措施，理解各种限流设计模式的设计的关键点，最后还需要根据具体的业务场景来选择合适模式。做好这些步骤，相信落地一个稳定可靠的限流器一定不会有太大问题。
