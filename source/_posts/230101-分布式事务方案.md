---
title: 分布式事务常用方案调研
img: 'http://pic.tanzhang.work/blog/gallary/230101.jpg!up.webp'
top: false
cover: false
toc: true
categories: 分布式
tags:
  - 事务
abbrlink: c5fea591
date: 2023-01-01 22:15:16
coverImg:
---
Base 理论将一致性划分出了 强一致性 和 最终一致性 的概念，基于这两种不同的一致性概念，产生了不同的分布式事务实现方案，比较常见的强一致性（刚性事务）实现方案有 XA、AT 等；而最终一致性（柔性事务）的常用方案有 TCC，SAGA 以及 可靠事件队列等。

## 刚性事务方案

### DTP 与 XA

DTP 模型是 X/Open 组织提出的一套分布式事务模型，其主要组成部分分为三部分，分别如下：

- AP（Application Program）：指应用程序，可以理解为使用 DTP 的程序；
- RM（Resource Manager）：局部资源管理器，用于驱动本地事务，在程序中存在一个或多个；
- TM（Transaction Manager）：全局事务管理器，用于协调全局事务，在程序中只有一个；

TM 提供给了 AP 应用程序一套标准的 TX 协议，用于事务的 开启、提交或回滚。

RM、TM 为了完成分布式事务，需要进行通信，为了解决这个问题，DTP 模型定义了一套标准的 XA 通信接口。XA 接口是双向的，能在一个事务管理器和多个资源管理器之间形成通信桥梁，通过协调多个数据源之间的动作，实现全局事务的统一提交或回滚。

XA 事务模式的实现就是基于 DTP 模型，其原理就是 2PC，以 TM 来作为全局事务的协调者，而 RM 则是参与者，TM 通过 XA 通信接口向所有的 RM 发起 准备提交 或 提交 的请求，而 RM 也通过 XA 通信接口来向 TM 反馈执行结果:
![XA 事务工作过程](http://pic.tanzhang.work/blog/20230102163822.png!up.webp)

由于 XA 事务是基于 2PC 来进行实现的，所以 2PC 存在的问题在 XA 中也基本存在，感兴趣的朋友可以阅读 [分布式事务基础理论](https://www.tanzhang.work/article/5838bdc8.html) 进行了解。

### AT 事务模式

AT 模式是阿里 seata 提出的基于 XA 事务的改良版本，其核心原理依然是 2PC。AT 模式主要由3部分组成：

- TC（Transaction coordinator）：事务协调者，用于维护全局事务的状态，驱动全局事务提交或回滚；
- TM（Tansaction Manager）：事务管理器，定义全局事务的范围：开启、提交或回滚全局事务；
- RM（Resource Manager）：管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。

AT 模式的工作过程如下图所示：
![AT 事务工作过程](http://pic.tanzhang.work/blog/20230102171327.png!up.webp)

AT 事务与 XA 事务的区别在于，AT 事务的回滚是**基于补偿**的，这点与后续提到的 SAGA 事务相似。首先由 TM 发起全局事务，RM 分支收到请求后，会先启动本地事务然后执行，并**生成回滚记录**；在本地事务提交前，RM 会先向 TC 注册事务分支，并申请对应的**全局锁**，拿到全局锁后，RM 会将分支事务提交，然后反馈给 TC 执行结果。当所有分支执行完毕后，TM 会再根据执行结果发起提交或回滚请求，由 TC 协调所有 RM 完成事务处理。

AT 事务相对于 XA 事务的优势在于补偿动作的引入。在准备阶段，XA 事务需要等待所有节点完成准备以后，才能进入提交阶段将本地事务提交，如果其中一个节点响应较慢，就会造成木桶效应，影响到其他节点的正常访问。而 AT 模式引入补偿以后，任意节点只要完成处理，都可以直接将事务提交，不存在延迟问题。

另外，AT 事务引入了全局锁，由 AT 事务所修改的数据，都需要先向 TC 申请对应的全局锁才能提交，且拿到全局锁以后，会持续到全局事务提交以后才会释放，从这点上看，AT 事务通过全局锁避免了“脏写”的问题。

不过在读取的时候，为了保证读取效率，AT 事务默认情况下并没有加任何锁，所以即使处于其他全局事务修改当中的数据，也可以被其他事务读取到，即实现的是“读未提交”隔离级别。

Seata 所实现 AT 事务模式在读取时也可以做额外处理，使读取时也获取到对应数据的全局锁。不过这种方式所获取的全局锁会增加锁冲突概率，阻塞其他事务对于对应数据的读写，导致数据写入和读取速率严重降低，并不推荐使用。

## 柔性事务方案

### 最大努力交付

最大可靠交付并不是最终一致性方案的具体实现方式，而是一种柔性事务思想，其原理如下图所示：
![最大可靠交付](http://pic.tanzhang.work/blog/20230102212835.png!up.webp)

生产者完成本地事务以后，发送一条可靠消息给到消费者，消费者收到消息后激活对应的处理流程，完成事务处理，如果还有下一级处理，会继续发送可靠消息给到下一级。

最大可靠交付的核心思想在于消息这个环节，为了实现消息的可靠交付，衍生出了多种方案，如本地消息表，可靠事件队列。

#### 本地消息表

本地消息表故名思意，就是在每个节点中都建立一张消息表，将本地事务操作和写入消息的动作放在一个本地事务中，这样可以保证消息写入表和本地事务能够同时成功或失败。

消息写入后，通过远程调用的方式来触发下一个节点的业务处理，如果调用成功，则将本地消息的状态改为已完成；反之如果调用失败了也没关系，后续可以通过定时任务扫描消息表，然后根据消息表的日志再进行远程调用触发下一节点业务，成功之后再更新消息状态。

同一消息如果被重复发送，会导致服务之间的业务执行产生幂等性问题。解决这个问题的常用设计是让消息带上一个唯一的事务id，以保证同一事务中的业务操作只会执行一次。

同一任务的重复触发具有最大次数限制，超出之后可以通过告警的方式通知人工处理。

#### 可靠事件队列

可靠事件队列 与 本地消息 一样，其形式也是属于最大努力交付，只是实现方式略有不同。

可靠事件队列需要使用到消息队列来进行实现，为了保证消息的可靠性，就需要保证消费者在投递消息时，能够正确的投递到队列中，入队以后的消息永远不会丢失，以及消息在被消费以后，能够正确的被 ack 掉，保证业务操作的幂等性。

#### 最大努力交付的缺点

从实现方式上来看，最大努力交付在消息发出去以后，上游事务就是已经提交的状态，无法回滚，所以消息一但发出，不管中间是否有错误，事务最终只能是成功的，无法进行回滚。

另一方面，最大努力交付模式在业务处理期间，没有对数据做任何处理，所以其他事务也可以同时修改同一数据，保证不了隔离性。在某些场景下没有隔离性是致命的，比如秒杀系统中可能导致超卖的问题。

### TCC 事务模式

TCC 是“Try-Confirm-Cancel”的缩写，故名思意，可以将它分为三部分：

- Try：尝试执行阶段，这个阶段会完成所有业务的可执行性检查（保障一致性），并且预留好全部需要用到的业务资源（保障隔离性）；
- Confirm：确认执行阶段，不会执行任何业务检查，直接 Try 阶段预留的资源完成业务处理。Confirm 阶段可能会重复执行，所以这一阶段所执行的操作需要具备幂等性；
- Cancel：取消执行阶段，释放 Confirm 阶段所预留的业务资源。Cancel 阶段也可能重复执行，需要满足幂等性。

TCC 事务模型的执行过程（Try 阶段所有节点均执行成功，记录 Confirm 日志）如下图所示：
![TCC 执行过程（所有节点在Try阶段均返回Confirm）](http://pic.tanzhang.work/blog/20230103223001.png!up.webp)

如果在 Try 阶段有任何一个节点执行失败记录下 Cancel 日志 或者 执行超时，则最后一阶段会将前面成功预留的资源全部释放。

#### TCC 的优缺点

从执行流程上看，TCC 事务模式有点像是 2PC，但 TCC 一般需要用户自己通过代码实现，而不是基础设施所自带的，因此，TCC 具有较高的灵活性，可以由用户自己控制操作的粒度大小。

但也正是因为其灵活性，带来了更高的开发成本和业务入侵，裸编程实现 TCC 是相当复杂的，通常我们需要结合一些中间件（如 seata）来实现，减轻一些编码的工作量。

TCC 预留业务资源的特性决定了其具有很好的隔离性，在事务操作过程中，不会涉及任何锁和资源争用，所以 TCC 的性能是非常优异的。

### SAGA 事务模式

TCC 事务具有很好的隔离性，其性能也是几种柔性事务中最好的，但是它并不能够满足所有场景，这是因为它对于业务的入侵性太强了。业务执行链路上如果有任何一个节点不在开发者的管控之下，TCC 方案就无法实施。例如一比支付业务，如果使用 TCC 事务方案的话，就涉及到银行方面的 冻结款项、解冻、扣减等操作，然而这些动作仅是我们设想好的，事实上银行并不一定会为我们实施 TCC 而专门去设计这种接口，所以 TCC 在这种场景下是很难落地的。

这种情况下，我们可以考虑采用另一种柔性事务方案：SAGA；

SAGA 的大致思路是将一个大事务拆解为一系列可以交错运行的子事务的集合，原本其设计的目的是为了避免大事务长时间锁定数据库的资源，后来才发展成将一个分布式环境中的大事务拆解为一系列本地事务的设计模式。

SAGA 的原理如下图所示：
![SAGA 执行过程](http://pic.tanzhang.work/blog/20230104155915.png!up.webp)

SAGA 组成主要由以下两部分组成：

- 大事务拆分为若干个小事务，将整个分布式事务 T 拆分为 n 个子事务，命名为 T1，T2，T3，...，Tn。如果分布式事务能够正常提交，其对于事务的最终影响（最终一致性）应该等价于 n 个子事务全部正常提交的结果；
- 为每个子事务设计补偿动作，命名为 C1，C2，C3，...，Cn，补偿动作与子事务需要满足一下要求：
  - Ti 与 Ci 需要满足交换律，即 Ci 可以完全还原 Ti 对数据的修改；
  - Ti 与 Ci 具备幂等性；
  - Ci 必须能执行成功，如果 Ci 执行失败，就必须持续重试直至成功，或由人工介入；

SAGA 的 T1 ~ Tn 如果都能执行成功，则事务顺利提交，如果中间有任意节点失败，就需要采取恢复策略。SAGA 的恢复策略有如下两种：

- 正向恢复：子事务从 T1 到 Ti-1 执行成功，Ti 执行失败，则需要对 Ti 持续重试直至成功位置（最大努力交付）。这种方式适用于不允许事务失败的场景。
- 反向恢复：子事务从 T1 到 Ti-1 执行成功，Ti 执行失败，则使用 Ci-1 到 C1 对 Ti-1 到 T1 进行反向补偿，消除 T1 到 Ti-1 对于数据的修改。如果任一补偿环节失败，则需要持续重试该环节直到成功为止。

SAGA 的重点在于补偿，而补偿动作的实现相比于 TCC 的 冻结动作 要简单的多。譬如在支付业务中，如果支付以后后续业务执行失败，我们无法要求银行撤销之前的转账操作，但是由我们的系统将账款转回用户的账户作为补偿措施却是完全可行的。

SAGA 执行需要所有子事务都能成功或补偿，但是 SAGA 本身也可能崩溃。为了保证崩溃后仍然能够找到事务恢复的节点，就需要记录事务日志（SAGA Log），已系统在恢复后能够追踪到子事务的执行情况，譬如执行到哪一步或补偿到哪一步了。

另外，为了保证恢复的过程能够严谨的进行也需要花费不少的功夫，例如幂等性的设计。鉴于这些难点，SAGA 通常也不会通过裸编码来实现，通常会结合一些中间件来（如 seata）来完成。

SAGA 解决了某些场景下 TCC 无法落地的问题，但代价就是极大的**牺牲了 隔离性**，甚至直接影响到了原子性。因为在缺乏隔离性的前提下，基于补偿的思路并不能总是保证成功的。譬如本地事务提交后，分布式事务完成前，该数据又被其他操作修改过了，产生了“脏写”，这时候一旦分布式事务需要回滚，就无法保证一定能够成功了。

## 结语

本章从刚性事务和柔性事务两个角度简单介绍了各种分布式事务实现方案的原理，从结果上来说，没有任何一种方案是完美的，每种方案都存在或多或少的缺点。不过在使用过程中，我们还是需要结合自身业务特点，去因地制宜的选择方案，大而全有时候并不一定是好事，合适的才是最好的。
